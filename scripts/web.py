import streamlit as st
import time
# å¯¼å…¥æ‚¨çš„åç«¯å‡½æ•°
from main import (
    load_llm,
    load_hybrid_indices,
    load_embedding_models,
    run_rag_system,
    add_to_history,
    CONVERSATION_HISTORY
)

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="COMP5423 RAG System",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– COMP5423 Group Project: RAG Chatbot")
st.markdown("Supports **Multi-Turn (Feature A)** & **Agentic Workflow (Feature B)**")


# --- 2. åˆå§‹åŒ–ç³»ç»Ÿ (ç¼“å­˜èµ„æºï¼Œé¿å…é‡å¤åŠ è½½) ---
@st.cache_resource
def init_system():
    load_llm()
    load_hybrid_indices()
    load_embedding_models()
    return True


with st.spinner("Loading Models & Indices... (This may take a minute)"):
    init_system()

# --- 3. åˆå§‹åŒ–èŠå¤©å†å² ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 4. æ˜¾ç¤ºå†å²æ¶ˆæ¯ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # å¦‚æœå†å²æ¶ˆæ¯é‡ŒåŒ…å«è¯æ®æˆ–æ—¥å¿—ï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæ¸²æŸ“
        if "logs" in message:
            with st.expander("ğŸ•µï¸ Agentic Workflow Logs (Reasoning & Verification)"):
                for log in message["logs"]:
                    st.info(log)
        if "docs" in message:
            with st.expander("ğŸ“š Retrieved Evidence (Source Documents)"):
                for i, doc in enumerate(message["docs"]):
                    st.markdown(f"**Doc {i + 1} (ID: {doc['id']})**")
                    st.text(doc['text'])

# --- 5. å¤„ç†ç”¨æˆ·è¾“å…¥ ---
if prompt := st.chat_input("Ask a question (e.g., Where was Obama born?)..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ˜¾ç¤ºåŠ©æ‰‹æ­£åœ¨æ€è€ƒ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        with st.spinner("Thinking & Retrieving..."):
            try:
                # è°ƒç”¨åç«¯ RAG ç³»ç»Ÿ
                # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ‚¨å·²ç»æŒ‰æ­¥éª¤2ä¿®æ”¹äº† run_rag_system ä»¥è¿”å› logs
                retrieved_docs, answer, effective_query, logs = run_rag_system(
                    prompt,
                    k=5,
                    is_multi_turn=True
                )

                # æ›´æ–°å…¨å±€å†å² (Feature A)
                add_to_history(effective_query, answer)

                # --- å±•ç¤º Bonus å†…å®¹ (Feature B) ---
                # ä½¿ç”¨ Expander æŠ˜å æ˜¾ç¤ºä¸­é—´è¿‡ç¨‹ï¼Œä¿æŒç•Œé¢æ•´æ´
                with st.expander("ğŸ•µï¸ Agentic Workflow Logs (Reasoning & Verification)", expanded=True):
                    for log in logs:
                        st.info(log)  # è“è‰²ä¿¡æ¯æ¡†æ˜¾ç¤ºæ—¥å¿—
                        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹çš„è§†è§‰æ•ˆæœ

                # --- å±•ç¤ºæ£€ç´¢ç»“æœ (Basic Requirement) ---
                # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„æ–‡æ¡£
                with st.expander("ğŸ“š Retrieved Evidence (Source Documents)"):
                    for i, doc in enumerate(retrieved_docs):
                        st.markdown(f"**Doc {i + 1} (ID: {doc['id']})**")
                        st.caption(doc['text'])  # ä½¿ç”¨ caption æ˜¾ç¤ºè¾ƒå°çš„æ–‡æœ¬
                        st.divider()

                # --- å±•ç¤ºæœ€ç»ˆç­”æ¡ˆ ---
                message_placeholder.markdown(answer)

                # å°†å®Œæ•´äº¤äº’ä¿å­˜åˆ° session state
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer,
                    "logs": logs,  # ä¿å­˜æ—¥å¿—ä»¥ä¾¿å†å²å›çœ‹
                    "docs": retrieved_docs  # ä¿å­˜æ–‡æ¡£ä»¥ä¾¿å†å²å›çœ‹
                })

            except Exception as e:
                st.error(f"An error occurred: {e}")