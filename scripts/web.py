import streamlit as st
import time
# å¯¼å…¥æ‚¨çš„åç«¯å‡½æ•°
from main import (
    load_llm,
    load_hybrid_indices,
    load_embedding_models,
    run_rag_system,
    add_to_history,
    CONVERSATION_HISTORY
)

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="COMP5423 RAG System",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– COMP5423 Group Project: RAG Chatbot")
st.markdown("Supports **Multi-Turn (Feature A)** & **Agentic Workflow (Feature B)**")


@st.cache_resource
def init_system():
    # çº¯åŠ è½½é€»è¾‘
    load_llm()
    load_hybrid_indices()
    load_embedding_models()
    return True


# åœ¨å¤–éƒ¨å¤„ç† UI åé¦ˆ
st.toast("ğŸš€ æ­£åœ¨åŠ è½½ LLMã€ç´¢å¼•å’ŒåµŒå…¥æ¨¡å‹ (ä»…é¦–æ¬¡è¿è¡Œ)...", icon="â³")

with st.spinner("Loading Models & Indices... (This may take a minute)"):
    # åœ¨ spinner å†…éƒ¨è°ƒç”¨ç¼“å­˜å‡½æ•°
    init_system()


# --- 3. åˆå§‹åŒ–èŠå¤©å†å² ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 4. æ˜¾ç¤ºå†å²æ¶ˆæ¯ (é»˜è®¤æŠ˜å æ—¥å¿—å’Œæ–‡æ¡£) ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # ä»…å½“å®ƒæ˜¯å¸¦å…ƒæ•°æ®çš„ System Answer æ—¶ï¼Œæ‰æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if message["role"] == "assistant" and "logs" in message:

            # å†å²è®°å½•é»˜è®¤æŠ˜å  (expanded=False)
            with st.expander("ğŸ•µï¸ Agentic Workflow Logs (Reasoning & Verification)", expanded=False):
                # å†å²æ—¥å¿—ï¼Œç®€å•æ˜¾ç¤º
                for log in message["logs"]:
                    st.info(log)

        if message["role"] == "assistant" and "docs" in message:
            # å†å²è®°å½•é»˜è®¤æŠ˜å  (expanded=False)
            with st.expander("ğŸ“š Retrieved Evidence (Source Documents)", expanded=False):
                for i, doc in enumerate(message["docs"]):
                    # å†å²è®°å½•ä¸­ä¹Ÿæ˜¾ç¤º RRF Score
                    score = doc.get('score', 0.0)
                    st.markdown(f"**Doc {i + 1}** (ID: `{doc['id']}`) **| RRF Score:** `{score:.4f}`")
                    st.caption(doc['text'])
                    st.divider()

# --- 5. å¤„ç†ç”¨æˆ·è¾“å…¥ ---
if prompt := st.chat_input("Ask a question (e.g., Where was Obama born?)..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ˜¾ç¤ºåŠ©æ‰‹æ­£åœ¨æ€è€ƒ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        with st.spinner("Thinking & Retrieving..."):
            try:
                # è°ƒç”¨åç«¯ RAG ç³»ç»Ÿ
                retrieved_docs, answer, effective_query, logs = run_rag_system(
                    prompt,
                    k=5,
                    is_multi_turn=True
                )

                # æ›´æ–°å…¨å±€å†å² (Feature A)
                add_to_history(effective_query, answer)

                # --- 1. ä»£ç†å·¥ä½œæµæ—¥å¿— (Feature B) ---
                # å½“å‰å›åˆé»˜è®¤å±•å¼€ logs (expanded=True)
                with st.expander("ğŸ•µï¸ Agentic Workflow Logs (CoT æ€è€ƒ & éªŒè¯)", expanded=True):
                    thinking_logs = [log for log in logs if 'Chain of Thought' in log or 'ğŸ§ ' in log]
                    verification_logs = [log for log in logs if 'Verification' in log or 'ğŸ›¡ï¸' in log or 'âœ…' in log]

                    if thinking_logs:
                        st.subheader("ğŸ§  Chain of Thought (æ€è€ƒè¿‡ç¨‹)")
                        # ä½¿ç”¨ st.code å±•ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œæ ¼å¼æ¸…æ™°
                        st.code('\n'.join(thinking_logs), language='markdown')

                    if verification_logs:
                        st.subheader("ğŸ›¡ï¸ Self-Verification (è‡ªéªŒè¯)")
                        for log in verification_logs:
                            # æ ¹æ®ç»“æœä½¿ç”¨ä¸åŒé¢œè‰²
                            if 'Passed' in log or 'âœ…' in log:
                                st.success(log)
                            elif 'Failed' in log or 'Warning' in log:
                                st.warning(log)
                            else:
                                st.info(log)

                # --- 2. æ£€ç´¢ç»“æœ (Hybrid Retrieval) ---
                # é»˜è®¤æŠ˜å æ–‡æ¡£ï¼Œé™¤éç”¨æˆ·æƒ³çœ‹
                with st.expander("ğŸ“š æ£€ç´¢åˆ°çš„æºæ–‡æ¡£ (Hybrid RRF Score)", expanded=False):
                    for i, doc in enumerate(retrieved_docs):
                        score = doc.get('score', 0.0)
                        st.markdown(f"**Doc {i + 1}** (ID: `{doc['id']}`) **| RRF Score:** `{score:.4f}`")
                        st.caption(doc['text'])
                        st.divider()

                # --- 3. å±•ç¤ºæœ€ç»ˆç­”æ¡ˆ ---
                message_placeholder.markdown(answer)

                # å°†å®Œæ•´äº¤äº’ä¿å­˜åˆ° session state
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer,
                    "logs": logs,  # ä¿å­˜æ—¥å¿—ä»¥ä¾¿å†å²å›çœ‹
                    "docs": retrieved_docs  # ä¿å­˜æ–‡æ¡£ä»¥ä¾¿å†å²å›çœ‹
                })

            except Exception as e:
                st.error(f"An error occurred: {e}")

        # å¼ºåˆ¶é‡æ–°è¿è¡Œä»¥æ›´æ–°ç•Œé¢
        st.rerun()